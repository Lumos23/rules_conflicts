{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "\n",
    "# workspace_path = os.getcwd()\n",
    "# root_dir_name = \"shallow-vs-deep-alignment\"\n",
    "\n",
    "# root_dir_st = workspace_path.find(root_dir_name)\n",
    "# workspace_path = workspace_path[:root_dir_st + len(root_dir_name)]\n",
    "# print(workspace_path)\n",
    "\n",
    "# # Add the parent directory to sys.path\n",
    "# sys.path.append(workspace_path)\n",
    "sys.path.append(\"/home/bw1822/Adaptive-Finetuning-Attacks/\")\n",
    "\n",
    "from finetuning_buckets.inference.safety_eval.chatgpt_judge_wmdp import ChatgptEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt_4_judge.ipynb', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw.json', 'batch.ipynb', 'images.jsonl', 'gpt_4_judge_azure.ipynb', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw_gpt_judge_responses.jsonl']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1273it [00:00, 156469.02it/s]\n",
      "1273it [00:00, 301811.60it/s]\n",
      "1273it [00:00, 281107.14it/s]\n",
      "1273it [00:00, 292438.88it/s]\n",
      "1273it [00:00, 287015.48it/s]\n",
      "1273it [00:00, 290766.70it/s]\n",
      "1273it [00:00, 260214.87it/s]\n",
      "1273it [00:00, 312388.78it/s]\n",
      "1273it [00:00, 284174.20it/s]\n",
      "408it [00:00, 419019.60it/s]\n",
      "408it [00:00, 469872.61it/s]\n",
      "408it [00:00, 473120.27it/s]\n",
      "408it [00:00, 385335.74it/s]\n",
      "408it [00:00, 426539.39it/s]\n",
      "408it [00:00, 8375.35it/s]\n",
      "408it [00:00, 399924.29it/s]\n",
      "408it [00:00, 450335.80it/s]\n",
      "408it [00:00, 454884.64it/s]\n",
      "1987it [00:00, 298050.28it/s]\n",
      "1987it [00:00, 360268.10it/s]\n",
      "1987it [00:00, 356721.40it/s]\n",
      "1987it [00:00, 297560.77it/s]\n",
      "1987it [00:00, 317839.98it/s]\n",
      "1987it [00:00, 312981.90it/s]\n",
      "1987it [00:00, 357655.22it/s]\n",
      "1987it [00:00, 360159.12it/s]\n",
      "1987it [00:00, 364682.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate batching files\n",
    "\n",
    "import os\n",
    "files = os.listdir('.')\n",
    "print(files)\n",
    "\n",
    "import json \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    if not file.endswith('.json'):\n",
    "        continue\n",
    "\n",
    "    batching_file_name = f'{file[:-5]}_gpt_judge_requests.jsonl'\n",
    "\n",
    "    if os.path.exists(batching_file_name):\n",
    "        print(f'{batching_file_name} already exists, skip')\n",
    "        continue\n",
    "\n",
    "    QApairs = []\n",
    "\n",
    "    with open(file) as f:\n",
    "        results_log = json.load(f)\n",
    "        # results_log = results_log['results']\n",
    "        for res in results_log:\n",
    "            # ans = res[-2]['content'] + \" \" + res[-1]['content']\n",
    "            # if res[0]['role'] == 'system':\n",
    "            #     qes = res[1]['content']\n",
    "            # else:\n",
    "            #     qes = res[0]['content']\n",
    "            qes = res['Question']\n",
    "            ans = res['Answer']\n",
    "            QApairs.append((qes, ans))\n",
    "    \n",
    "    \n",
    "    ChatgptEvaluator.duo_judge_batching(QApairs, batching_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt_4_judge.ipynb', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'batch.ipynb', 'images.jsonl', 'gpt_4_judge_azure.ipynb', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw_gpt_judge_responses.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw_gpt_judge_requests.jsonl']\n",
      "file-12eaf9f88dc1433081c5e28938db918b\n",
      "retrying\n",
      "Batch(id='batch_44709b8f-1f9a-4f80-8912-42160f72d743', completion_window='24h', created_at=1730067383, endpoint='/chat/completions', input_file_id='file-12eaf9f88dc1433081c5e28938db918b', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153783, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-b0bfe6f049d84e6a9c40b5a060d3c34e\n",
      "retrying\n",
      "retrying\n",
      "Batch(id='batch_55447142-aa1b-4413-b934-70d9bf7754d0', completion_window='24h', created_at=1730067394, endpoint='/chat/completions', input_file_id='file-b0bfe6f049d84e6a9c40b5a060d3c34e', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153794, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-bdf730ccdea042c5848abc28346afb09\n",
      "retrying\n",
      "Batch(id='batch_16d07e95-96ad-4af8-b952-8a0b86c0c916', completion_window='24h', created_at=1730067399, endpoint='/chat/completions', input_file_id='file-bdf730ccdea042c5848abc28346afb09', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153799, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-26e253320aa346c598cdb5b5b6ffb293\n",
      "retrying\n",
      "Batch(id='batch_7e1b14d7-cf23-4e51-8dfc-9b462c5d8762', completion_window='24h', created_at=1730067405, endpoint='/chat/completions', input_file_id='file-26e253320aa346c598cdb5b5b6ffb293', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153805, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-3ffbf3c332ab4b1f8e47966f729ca9ba\n",
      "retrying\n",
      "Batch(id='batch_41202c22-dd0d-4021-8295-13538130caf6', completion_window='24h', created_at=1730067410, endpoint='/chat/completions', input_file_id='file-3ffbf3c332ab4b1f8e47966f729ca9ba', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153810, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-4cbb1752cc9c4f038ce91297ed90da4e\n",
      "retrying\n",
      "Batch(id='batch_f7a25a71-6eb1-4563-baeb-4b5fd06c048c', completion_window='24h', created_at=1730067415, endpoint='/chat/completions', input_file_id='file-4cbb1752cc9c4f038ce91297ed90da4e', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153815, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-3acb2aa9b00f4f0f8faf0e8975005ec8\n",
      "retrying\n",
      "Batch(id='batch_f20b1a82-0543-4a12-af3f-2df56e9597e1', completion_window='24h', created_at=1730067421, endpoint='/chat/completions', input_file_id='file-3acb2aa9b00f4f0f8faf0e8975005ec8', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153821, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-3334f739a2ba4c50b76cdae869882410\n",
      "retrying\n",
      "Batch(id='batch_87a69d84-184c-4469-89cc-ee0464fb2340', completion_window='24h', created_at=1730067427, endpoint='/chat/completions', input_file_id='file-3334f739a2ba4c50b76cdae869882410', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153827, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-adbb8f81d9ee432f808d9e5a29850a22\n",
      "retrying\n",
      "Batch(id='batch_a702d74a-c835-4907-8fcc-f52c2135e2fc', completion_window='24h', created_at=1730067432, endpoint='/chat/completions', input_file_id='file-adbb8f81d9ee432f808d9e5a29850a22', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153832, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-19271a78c04d48ccadd0100ad7fd8164\n",
      "retrying\n",
      "Batch(id='batch_86429d5f-c965-4038-a48f-ac7092d6b686', completion_window='24h', created_at=1730067437, endpoint='/chat/completions', input_file_id='file-19271a78c04d48ccadd0100ad7fd8164', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153837, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-eb2faa478f104392bab6c161ba3227f0\n",
      "Batch(id='batch_0afd0b0f-dfbd-438e-a408-99ec6eb3befd', completion_window='24h', created_at=1730067443, endpoint='/chat/completions', input_file_id='file-eb2faa478f104392bab6c161ba3227f0', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153843, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-a233db19c3ee47b0a8d0bf930311b97a\n",
      "retrying\n",
      "Batch(id='batch_c9a6a64e-3d62-48fa-a61c-648f4e73f262', completion_window='24h', created_at=1730067449, endpoint='/chat/completions', input_file_id='file-a233db19c3ee47b0a8d0bf930311b97a', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153849, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-18e8958529c5409a9633b73cba37f8c4\n",
      "retrying\n",
      "Batch(id='batch_86b1f502-13b0-4898-bb17-a9a3f84c1549', completion_window='24h', created_at=1730067454, endpoint='/chat/completions', input_file_id='file-18e8958529c5409a9633b73cba37f8c4', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153854, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-ee59d997f6c442528a392c6e6d746c25\n",
      "retrying\n",
      "Batch(id='batch_6b61b095-b626-4c65-93bf-7a60f75c80a1', completion_window='24h', created_at=1730067459, endpoint='/chat/completions', input_file_id='file-ee59d997f6c442528a392c6e6d746c25', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153859, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-2d23742942c64160b523e694a93adc8a\n",
      "retrying\n",
      "Batch(id='batch_7ddace49-3f12-4914-b88f-5f40858ae878', completion_window='24h', created_at=1730067465, endpoint='/chat/completions', input_file_id='file-2d23742942c64160b523e694a93adc8a', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153865, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-7f8aef5b3be44286935c861a26622140\n",
      "retrying\n",
      "Batch(id='batch_954444f6-4ec8-4d3d-b4ff-edd4b4d295e4', completion_window='24h', created_at=1730067470, endpoint='/chat/completions', input_file_id='file-7f8aef5b3be44286935c861a26622140', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153870, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-75685fca76e441d69a880b906b2be0d5\n",
      "retrying\n",
      "Batch(id='batch_fa2f5f13-6c50-421d-a448-127de4e7af74', completion_window='24h', created_at=1730067475, endpoint='/chat/completions', input_file_id='file-75685fca76e441d69a880b906b2be0d5', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153875, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-6b2419c253c94343a515b7a0c86eeece\n",
      "retrying\n",
      "Batch(id='batch_ea104388-9332-4d41-92d1-7cb34d82119d', completion_window='24h', created_at=1730067480, endpoint='/chat/completions', input_file_id='file-6b2419c253c94343a515b7a0c86eeece', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153880, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-fea63427fe204a48b56704f87f9da6d1\n",
      "retrying\n",
      "Batch(id='batch_8e854e2e-fb48-46e1-add6-e14ffec22003', completion_window='24h', created_at=1730067485, endpoint='/chat/completions', input_file_id='file-fea63427fe204a48b56704f87f9da6d1', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153885, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-86bf6a7826bf47ed992f1e436f55d14c\n",
      "retrying\n",
      "Batch(id='batch_83530f52-71e2-4cf7-9080-2616bf531535', completion_window='24h', created_at=1730067491, endpoint='/chat/completions', input_file_id='file-86bf6a7826bf47ed992f1e436f55d14c', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153891, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-2d79c525cd074842b231559895a01ee8\n",
      "retrying\n",
      "Batch(id='batch_6d7de14b-e733-4987-bada-af08da8f630a', completion_window='24h', created_at=1730067496, endpoint='/chat/completions', input_file_id='file-2d79c525cd074842b231559895a01ee8', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153896, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-e7b1ecbc1be24160a0ca6f6680670fcc\n",
      "retrying\n",
      "Batch(id='batch_afc98b7e-2e0c-4b01-bb99-e4bcb4bcc76d', completion_window='24h', created_at=1730067501, endpoint='/chat/completions', input_file_id='file-e7b1ecbc1be24160a0ca6f6680670fcc', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153901, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-593536254e2c475c97b0d2fd9e46a326\n",
      "retrying\n",
      "Batch(id='batch_aa1a42a4-ad35-4382-a55e-5874e132d34e', completion_window='24h', created_at=1730067508, endpoint='/chat/completions', input_file_id='file-593536254e2c475c97b0d2fd9e46a326', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153908, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-55abb49a258b40f0959c0c987fc836b7\n",
      "retrying\n",
      "Batch(id='batch_d3e3dcc6-ecae-4028-86f1-42f7a7dc0b9b', completion_window='24h', created_at=1730067516, endpoint='/chat/completions', input_file_id='file-55abb49a258b40f0959c0c987fc836b7', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153916, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-cc93690c940548c38cfb8b49aac2ca4c\n",
      "retrying\n",
      "Batch(id='batch_fb44ff75-7679-4b75-86a8-edc05e58484f', completion_window='24h', created_at=1730067521, endpoint='/chat/completions', input_file_id='file-cc93690c940548c38cfb8b49aac2ca4c', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153921, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-d5ef783891cd4d96a22ef5686df0b492\n",
      "retrying\n",
      "Batch(id='batch_b8d5b298-c2ad-44d7-bd43-d48d035e4731', completion_window='24h', created_at=1730067526, endpoint='/chat/completions', input_file_id='file-d5ef783891cd4d96a22ef5686df0b492', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153926, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-c2fde6c7ab1c4a588a697b3b7ae64f4d\n",
      "retrying\n",
      "Batch(id='batch_e5309c3e-e270-4554-a838-33a345869e16', completion_window='24h', created_at=1730067531, endpoint='/chat/completions', input_file_id='file-c2fde6c7ab1c4a588a697b3b7ae64f4d', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1730153931, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import time\n",
    "\n",
    "# Set up Azure OpenAI API credentials\n",
    "openai.api_type = \"azure\"\n",
    "# openai.api_base = \"https://pliopenaieu2.openai.azure.com/\"  # Replace with your Azure resource URL\n",
    "openai.api_base = \"https://pliopenaisc.openai.azure.com/\"\n",
    "# openai.api_version = \"2024-04-01-preview\"  # Use the appropriate API version\n",
    "openai.api_key = \"7d5c82ec3b83427cab1df6c2cf465e40\"  # Replace with your Azure OpenAI API key\n",
    "openai.azure_deployment=\"gpt-4o-2024-05-13\"\n",
    "\n",
    "files = os.listdir('.')\n",
    "print(files)\n",
    "\n",
    "client = AzureOpenAI(\n",
    "        azure_endpoint = openai.api_base,\n",
    "        api_key= openai.api_key,\n",
    "        api_version=\"2024-07-01-preview\",\n",
    "        # timeout=240,\n",
    "        # max_retries=2\n",
    "    )\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    if not file.endswith('.json'):\n",
    "        continue\n",
    "\n",
    "    submit_history_path = f'{file[:-5]}_gpt_judge_submission_log.jsonl'\n",
    "    batching_file_name = f'{file[:-5]}_gpt_judge_requests.jsonl'\n",
    "    results_file_name = f'{file[:-5]}_gpt_judge_responses.jsonl'\n",
    "\n",
    "    if os.path.exists(submit_history_path):\n",
    "        print(f'{submit_history_path} already exists, skip')\n",
    "        continue\n",
    "    \n",
    "    uploaded_file = client.files.create(\n",
    "        file=open(batching_file_name, \"rb\"),\n",
    "        purpose='batch'\n",
    "    )\n",
    "    print(uploaded_file.id)\n",
    "    \n",
    "    for  i in range(16):\n",
    "        try:\n",
    "            response = client.batches.create(\n",
    "                input_file_id = uploaded_file.id,\n",
    "                completion_window = \"24h\",\n",
    "                endpoint = \"/v1/chat/completions\"\n",
    "            )\n",
    "            print(response)\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(3)\n",
    "            print(\"retrying\")\n",
    "    \n",
    "    submission_log = {\n",
    "        'uploaded_file_id': uploaded_file.id,\n",
    "        'batch_job_id': response.id,\n",
    "    }\n",
    "\n",
    "    with open(submit_history_path, 'w') as f:\n",
    "        f.write(json.dumps(submission_log) + '\\n')\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt_4_judge.ipynb', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw.json', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw_gpt_judge_submission_log.jsonl', 'gpt_4_judge_azure.ipynb', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw_gpt_judge_responses.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_1-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2_seed_3-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2_seed_2-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_1-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_2-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-chattemp_seed_3-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_1-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_2-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-v2-nobos-nochattemp_seed_3-nosys+raw_gpt_judge_submission_log.jsonl']\n",
      "batch_job_id :  batch_75518d1d-44c9-4550-827c-28fae7b416e4\n",
      "response :  Batch(id='batch_75518d1d-44c9-4550-827c-28fae7b416e4', completion_window='24h', created_at=1730064292, endpoint='/chat/completions', input_file_id='file-e2fa66bb0a4e4838a87d9ff0c6895c71', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150692, failed_at=1730064426, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_2c1829fd-72f0-4ab5-b920-2c79bb1091a6\n",
      "response :  Batch(id='batch_2c1829fd-72f0-4ab5-b920-2c79bb1091a6', completion_window='24h', created_at=1730064298, endpoint='/chat/completions', input_file_id='file-6f3d0145873f400dbb2fbbb3af935a74', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150698, failed_at=1730064384, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_5e4119e0-0ac2-4d54-bffa-17996369299b\n",
      "response :  Batch(id='batch_5e4119e0-0ac2-4d54-bffa-17996369299b', completion_window='24h', created_at=1730064307, endpoint='/chat/completions', input_file_id='file-16bc3278fafe49aa85d2f9c6e8791d53', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150707, failed_at=1730064427, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_9a11123e-e606-4d73-b372-91377a4e0146\n",
      "response :  Batch(id='batch_9a11123e-e606-4d73-b372-91377a4e0146', completion_window='24h', created_at=1730064312, endpoint='/chat/completions', input_file_id='file-e7999d83315346588c086beb7a54ff7e', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150712, failed_at=1730064427, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_e5efa223-52a9-40f4-bd38-c7921c410e5c\n",
      "response :  Batch(id='batch_e5efa223-52a9-40f4-bd38-c7921c410e5c', completion_window='24h', created_at=1730064323, endpoint='/chat/completions', input_file_id='file-1a962bf814094f2ea0707731e99305f5', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150723, failed_at=1730064439, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_cffee027-6b2b-48b1-a508-de20dd57d5fa\n",
      "response :  Batch(id='batch_cffee027-6b2b-48b1-a508-de20dd57d5fa', completion_window='24h', created_at=1730064328, endpoint='/chat/completions', input_file_id='file-fc4aac033a3d4d3bb662e696804715d3', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150728, failed_at=1730064426, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_4e55a1fe-2013-4dc7-8226-eaed60c4d074\n",
      "response :  Batch(id='batch_4e55a1fe-2013-4dc7-8226-eaed60c4d074', completion_window='24h', created_at=1730064334, endpoint='/chat/completions', input_file_id='file-894bbf6268434c93a003626c15d73931', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150734, failed_at=1730064425, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_f00275ea-c752-47d6-ae49-9c7aade2b0e7\n",
      "response :  Batch(id='batch_f00275ea-c752-47d6-ae49-9c7aade2b0e7', completion_window='24h', created_at=1730064339, endpoint='/chat/completions', input_file_id='file-a6e2f601f033409f82d6fd453dba2bfc', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150739, failed_at=1730064426, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_321f2750-2ab7-450c-a4a2-507376504dcb\n",
      "response :  Batch(id='batch_321f2750-2ab7-450c-a4a2-507376504dcb', completion_window='24h', created_at=1730064344, endpoint='/chat/completions', input_file_id='file-dc67485d16de4b4ebbff9d1ce35d6097', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150744, failed_at=1730064432, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_07b8f211-6bc8-4c21-a671-f1429853e443\n",
      "response :  Batch(id='batch_07b8f211-6bc8-4c21-a671-f1429853e443', completion_window='24h', created_at=1730064349, endpoint='/chat/completions', input_file_id='file-54ec53f3e0dc4362b7f13698abb42f4b', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150749, failed_at=1730064427, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_72109223-97ae-43a1-9cda-0881ec8b0a81\n",
      "response :  Batch(id='batch_72109223-97ae-43a1-9cda-0881ec8b0a81', completion_window='24h', created_at=1730064354, endpoint='/chat/completions', input_file_id='file-e4cf767f46b44acc87ab10f0e4c0daa4', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150754, failed_at=1730064426, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_6ecc97f9-3fa1-4ee0-a67b-eac294bad62c\n",
      "response :  Batch(id='batch_6ecc97f9-3fa1-4ee0-a67b-eac294bad62c', completion_window='24h', created_at=1730064362, endpoint='/chat/completions', input_file_id='file-dc01e81ea19d47dcb30795b4a29ec671', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150762, failed_at=1730064425, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_2fea5985-b0f8-4a1e-bddb-4f81b934a986\n",
      "response :  Batch(id='batch_2fea5985-b0f8-4a1e-bddb-4f81b934a986', completion_window='24h', created_at=1730064367, endpoint='/chat/completions', input_file_id='file-5e1295fb59274abb8f982950d8e2c1b2', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150767, failed_at=1730064439, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_0416684b-83e9-4028-8d31-d51c259e24ad\n",
      "response :  Batch(id='batch_0416684b-83e9-4028-8d31-d51c259e24ad', completion_window='24h', created_at=1730064372, endpoint='/chat/completions', input_file_id='file-e3510abc72b24e8ea501bd6ed58635ac', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150772, failed_at=1730064441, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_842b9b11-2224-4091-ad96-8b27161a9e4a\n",
      "response :  Batch(id='batch_842b9b11-2224-4091-ad96-8b27161a9e4a', completion_window='24h', created_at=1730064377, endpoint='/chat/completions', input_file_id='file-843ae5e76d0741aea69db0f6300f6a69', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150777, failed_at=1730064444, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_14e93d43-46ac-437c-81d9-bc1c18a41228\n",
      "response :  Batch(id='batch_14e93d43-46ac-437c-81d9-bc1c18a41228', completion_window='24h', created_at=1730064381, endpoint='/chat/completions', input_file_id='file-85393fa20e5e4a38b613f6e508eaed01', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150781, failed_at=1730064444, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_cd38ac35-8408-44e6-92af-27fbe7177125\n",
      "response :  Batch(id='batch_cd38ac35-8408-44e6-92af-27fbe7177125', completion_window='24h', created_at=1730064389, endpoint='/chat/completions', input_file_id='file-df01b29d530c4d3ca0baa40d4871f83b', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150789, failed_at=1730064462, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_1fc9150d-e35d-427c-9209-ccf45599fa46\n",
      "response :  Batch(id='batch_1fc9150d-e35d-427c-9209-ccf45599fa46', completion_window='24h', created_at=1730064394, endpoint='/chat/completions', input_file_id='file-67164cbd18e04bd096f5439e457cda63', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150794, failed_at=1730064461, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_6acf5c41-a171-46be-be33-51d1915795e8\n",
      "response :  Batch(id='batch_6acf5c41-a171-46be-be33-51d1915795e8', completion_window='24h', created_at=1730064400, endpoint='/chat/completions', input_file_id='file-2428bb6fd9f2435c81c7e3130aafda81', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150800, failed_at=1730064473, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_b616f012-d9c4-426f-9d9f-132e94f73ad7\n",
      "response :  Batch(id='batch_b616f012-d9c4-426f-9d9f-132e94f73ad7', completion_window='24h', created_at=1730064405, endpoint='/chat/completions', input_file_id='file-143401b4fc3c4170982146f11567434c', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150805, failed_at=1730064500, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_4a501743-2ad3-4c8f-8871-b260e5aa3c69\n",
      "response :  Batch(id='batch_4a501743-2ad3-4c8f-8871-b260e5aa3c69', completion_window='24h', created_at=1730064411, endpoint='/chat/completions', input_file_id='file-1e9ad08b752445319626a2661f90587b', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150811, failed_at=1730064517, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_a92540dc-c965-4500-8656-9bcca5ecc114\n",
      "response :  Batch(id='batch_a92540dc-c965-4500-8656-9bcca5ecc114', completion_window='24h', created_at=1730064416, endpoint='/chat/completions', input_file_id='file-2adb70b5c8324e4dba6ccf6dbf759435', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150816, failed_at=1730064492, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_e976860a-6716-4906-a5a4-52af4b44b907\n",
      "response :  Batch(id='batch_e976860a-6716-4906-a5a4-52af4b44b907', completion_window='24h', created_at=1730064421, endpoint='/chat/completions', input_file_id='file-9381ff2a24af4d4f8dbd0dcfa398c3df', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150821, failed_at=1730064533, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_8eb44b1d-d19f-4646-bf27-46cd1fb15288\n",
      "response :  Batch(id='batch_8eb44b1d-d19f-4646-bf27-46cd1fb15288', completion_window='24h', created_at=1730064427, endpoint='/chat/completions', input_file_id='file-fc5d2335a3d84a3c8f5f3acd649ebef4', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150827, failed_at=1730064490, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_acc60c52-77b9-4cf1-8d50-42dae889e96f\n",
      "response :  Batch(id='batch_acc60c52-77b9-4cf1-8d50-42dae889e96f', completion_window='24h', created_at=1730064432, endpoint='/chat/completions', input_file_id='file-bfa2f6bf0c72458ca45d0ef599272ef0', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150832, failed_at=1730064500, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_d8731652-4ca4-4feb-b26d-2d2568478341\n",
      "response :  Batch(id='batch_d8731652-4ca4-4feb-b26d-2d2568478341', completion_window='24h', created_at=1730064437, endpoint='/chat/completions', input_file_id='file-298904f7c5704949822627f00c9eb767', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150837, failed_at=1730064586, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "batch_job_id :  batch_eca33a37-3352-4bb0-8277-e110c57397d5\n",
      "response :  Batch(id='batch_eca33a37-3352-4bb0-8277-e110c57397d5', completion_window='24h', created_at=1730064444, endpoint='/chat/completions', input_file_id='file-d63bf4a3e05a404bbb0d11b258c843f1', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='invalid_request', line=None, message=\"Invalid deployment SKU 'GlobalStandard'. The deployment SKU needs to be 'Global-Batch' for batch API requests. Learn more: https://aka.ms/aoai_batch/errors.\", param=None)], object='list'), expired_at=None, expires_at=1730150844, failed_at=1730064596, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "output_file_id is None, skip\n",
      "[completed]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# retrieve jobs\n",
    "from openai import AzureOpenAI\n",
    "import openai\n",
    "import json\n",
    "# Add the parent directory to sys.path\n",
    "# sys.path.append('/scratch/gpfs/xq8121/Controlled-Finetuning')\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "sys.path.append(\"/home/bw1822/Adaptive-Finetuning-Attacks/\")\n",
    "\n",
    "from finetuning_buckets.inference.safety_eval.chatgpt_judge import ChatgptEvaluator\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "files = os.listdir('.')\n",
    "print(files)\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "# openai.api_base = \"https://pliopenaieu2.openai.azure.com/\"  # Replace with your Azure resource URL\n",
    "openai.api_base = \"https://pliopenaisc.openai.azure.com/\"\n",
    "# openai.api_version = \"2024-04-01-preview\"  # Use the appropriate API version\n",
    "openai.api_key = \"7d5c82ec3b83427cab1df6c2cf465e40\"  # Replace with your Azure OpenAI API key\n",
    "openai.azure_deployment=\"gpt-4o-2024-05-13\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "        azure_endpoint = openai.api_base,\n",
    "        api_key= openai.api_key,\n",
    "        api_version=\"2024-07-01-preview\",\n",
    "    )\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    if not file.endswith('.json'):\n",
    "        continue\n",
    "    \n",
    "    submit_history_path = f'{file[:-5]}_gpt_judge_submission_log.jsonl'\n",
    "    results_save_path = f'{file[:-5]}_gpt_judge_results.jsonl'\n",
    "    intermidiate_results_save_path = f'{file[:-5]}_gpt_judge_intermidiate_results.jsonl'\n",
    "\n",
    "    if os.path.exists(results_save_path):\n",
    "        print(f'{results_save_path} already exists, skip')\n",
    "        continue\n",
    "    \n",
    "\n",
    "    results = {}\n",
    "\n",
    "    \n",
    "    with open(file) as f:\n",
    "        results_log = json.load(f)\n",
    "        \n",
    "        # results_log = results_log['results']\n",
    "        for i, res in enumerate(results_log):\n",
    "            qes = res['Question']\n",
    "            ans = res['Answer']\n",
    "            # QApairs.append((qes, ans))\n",
    "            # ans = res[-2]['content'] + \" \" + res[-1]['content']\n",
    "            # if res[0]['role'] == 'system':\n",
    "            #     qes = res[1]['content']\n",
    "            # else:\n",
    "            #     qes = res[0]['content']\n",
    "            results[f\"request-{i}\"] = {\"question\": qes, \"answer\": ans}\n",
    "            \n",
    "\n",
    "    with open(submit_history_path) as f:\n",
    "        submission_log = json.load(f)\n",
    "        batch_job_id = submission_log['batch_job_id']\n",
    "        response = client.batches.retrieve(batch_id = batch_job_id)\n",
    "        print('batch_job_id : ', batch_job_id)\n",
    "        print('response : ', response)\n",
    "        output_file_id = response.output_file_id\n",
    "        if output_file_id is None:\n",
    "            print('output_file_id is None, skip')\n",
    "            continue\n",
    "        \n",
    "        file_response = client.files.content(output_file_id)\n",
    "        # response_file = openai.files.retrieve_content(output_file_id)\n",
    "\n",
    "\n",
    "    with open(intermidiate_results_save_path, 'w') as f:\n",
    "        f.write(response_file)\n",
    "\n",
    "    with open(intermidiate_results_save_path) as f:\n",
    "        for line in f:\n",
    "            line = json.loads(line)\n",
    "            #print(line)\n",
    "            entry_id = line[\"custom_id\"]\n",
    "            completion = line[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "            #print(completion)\n",
    "            #score = ChatgptEvaluator.extract_content(\"#thescore:\", completion) \n",
    "            #print(score)\n",
    "            try:\n",
    "                answer = ChatgptEvaluator.extract_content(\"#theanswer:\", completion) \n",
    "                results[entry_id][\"answer\"] = answer\n",
    "            except:\n",
    "                results[entry_id][\"answer\"] = completion\n",
    "                print('bad_answer: ', completion)\n",
    "\n",
    "    with open(results_save_path, 'w') as f:\n",
    "        for key in results.keys():\n",
    "            f.write(json.dumps(results[key]) + '\\n')\n",
    "\n",
    "\n",
    "print('[completed]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wmdp_bio+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw.json', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw.json', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw.json', 'gpt_4_judge.ipynb', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_requests.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_submission_log.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'wmdp_chem+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_results.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'wmdp_bio+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_results.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'wmdp_cyber+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_results.jsonl']\n",
      "wmdp_bio+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_results.jsonl\n",
      "wmdp_bio+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_results.jsonl score = 0.5090337784760408\n",
      "wmdp_chem+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_results.jsonl\n",
      "wmdp_chem+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_results.jsonl score = 0.45098039215686275\n",
      "wmdp_cyber+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_results.jsonl\n",
      "wmdp_cyber+llama3-8b-Instruct-TAR-Bio-Chat-Template-nosys+raw_gpt_judge_results.jsonl score = 0.3029693004529441\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "files = os.listdir('.')\n",
    "print(files)\n",
    "\n",
    "files.sort()\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    if not file.endswith('.json'):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    results_save_path = f'{file[:-5]}_gpt_judge_results.jsonl'\n",
    "    print(results_save_path)\n",
    "    \n",
    "\n",
    "    if not os.path.exists(results_save_path):\n",
    "        print(f'{results_save_path} not ready yet, skip')\n",
    "        continue\n",
    "    \n",
    "\n",
    "    with open(results_save_path) as f:\n",
    "        results = [json.loads(line) for line in f]\n",
    "    if 'wmdp_bio' in results_save_path:\n",
    "        dataset = pd.read_parquet(\"/home/bw1822/Adaptive-Finetuning-Attacks/finetuning_buckets/datasets/safety_datasets/wmdp/wmdp-bio.parquet\")\n",
    "    elif 'wmdp_chem' in results_save_path:\n",
    "        dataset = pd.read_parquet(\"/home/bw1822/Adaptive-Finetuning-Attacks/finetuning_buckets/datasets/safety_datasets/wmdp/wmdp-chem.parquet\")\n",
    "    elif 'wmdp_cyber' in results_save_path:\n",
    "        dataset = pd.read_parquet(\"/home/bw1822/Adaptive-Finetuning-Attacks/finetuning_buckets/datasets/safety_datasets/wmdp/wmdp-cyber.parquet\")\n",
    "    raw_gts = dataset['answer'].to_list()\n",
    "    candidates = ['A', 'B', 'C', 'D']\n",
    "    gts = [candidates[raw_gts[i]] for i in range(len(raw_gts))]\n",
    "    scores = []\n",
    "    for i in range(len(results)):\n",
    "        res = results[i]\n",
    "        answer = res['answer']\n",
    "        gt = gts[i]\n",
    "        if gt == answer:\n",
    "            score = 1\n",
    "        else:\n",
    "            score = 0\n",
    "        scores.append(float(score))\n",
    "    \n",
    "    scores = np.array(scores, dtype=float)\n",
    "    print(f'{results_save_path} score = {np.mean(scores)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
